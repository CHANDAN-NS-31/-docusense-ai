{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8a91e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -U langchain langchain-community sentence-transformers faiss-cpu pymupdf python-dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f7fef238",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ STEP 2: Imports\n",
    "import os\n",
    "import time\n",
    "import textwrap\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from utils import redact_sensitive_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "59e362f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ STEP 3: Load API Key from .env\n",
    "load_dotenv()\n",
    "API_KEY = os.getenv(\"OPENROUTER_API_KEY\")\n",
    "MODEL = \"meta-llama/llama-3-8b-instruct\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2861e341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîë API Key loaded: sk-or-v1\n"
     ]
    }
   ],
   "source": [
    "# Debug print to verify API key is loaded\n",
    "print(\"üîë API Key loaded:\", API_KEY[:8] if API_KEY else \"‚ùå NOT LOADED\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c36ae253",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ STEP 4: Define OpenRouter API Function\n",
    "def call_openrouter_api(prompt):\n",
    "    url = \"https://openrouter.ai/api/v1/chat/completions\"\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {API_KEY}\",\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"HTTP-Referer\": \"https://chat.openai.com\",\n",
    "        \"X-Title\": \"PDF-QA-App\"\n",
    "    }\n",
    "    payload = {\n",
    "        \"model\": MODEL,\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": prompt}]\n",
    "    }\n",
    "    try:\n",
    "        response = requests.post(url, headers=headers, json=payload, timeout=30)\n",
    "        if response.status_code == 200:\n",
    "            return response.json()[\"choices\"][0][\"message\"][\"content\"]\n",
    "        else:\n",
    "            raise Exception(f\"API Error {response.status_code}: {response.text}\")\n",
    "    except requests.exceptions.Timeout:\n",
    "        raise Exception(\"‚è±Ô∏è Request timed out. Try again or reduce context size.\")\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"‚ùå Failed to call OpenRouter API: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e89d3d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_question_from_pdf(query, retriever, selected_pdf):\n",
    "    results = retriever.get_relevant_documents(query)\n",
    "    context = \"\\n\\n\".join([doc.page_content for doc in results[:3]])\n",
    "    context = redact_sensitive_info(context)\n",
    "    prompt = f\"\"\"You are a helpful assistant. Use the following PDF content to answer the question.\n",
    "\n",
    "üìò Context:\n",
    "{context}\n",
    "\n",
    "‚ùì Question:\n",
    "{query}\n",
    "\n",
    "üß† Answer:\"\"\"\n",
    "    prompt = redact_sensitive_info(prompt)\n",
    "    response = call_openrouter_api(prompt)\n",
    "\n",
    "    # Log the conversation\n",
    "    with open(\"qa_log.txt\", \"a\") as f:\n",
    "        f.write(f\"\\nPDF: {selected_pdf}\\nQ: {query}\\nA:\\n{response}\\n{'-'*50}\\n\")\n",
    "\n",
    "    # Nicely print the response\n",
    "    print(\"\\nüîç Answer:\\n\")\n",
    "    for line in textwrap.wrap(response.strip(), width=80):\n",
    "        print(line)\n",
    "        time.sleep(0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "84ab1ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ STEP 5: Load and Process PDFs\n",
    "pdf_dir = \"pdfs\"\n",
    "filenames = [os.path.join(pdf_dir, f) for f in os.listdir(pdf_dir) if f.endswith(\".pdf\")]\n",
    "splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "retrievers = {}\n",
    "\n",
    "for fname in filenames:\n",
    "    loader = PyMuPDFLoader(fname)\n",
    "    docs = splitter.split_documents(loader.load())\n",
    "    db = FAISS.from_documents(docs, embeddings)\n",
    "    retrievers[fname] = db.as_retriever()\n",
    "\n",
    "# ‚úÖ STEP 6: Q&A Function\n",
    "def ask_question_from_pdf(query, retriever, selected_pdf):\n",
    "    results = retriever.get_relevant_documents(query)\n",
    "    context = \"\\n\\n\".join([doc.page_content for doc in results[:2]])  # use top 2 chunks for speed\n",
    "    context = redact_sensitive_info(context)\n",
    "    prompt = f\"\"\"You are a helpful assistant. Use the following PDF content to answer the question.\n",
    "\n",
    "üìò Context:\n",
    "{context}\n",
    "\n",
    "‚ùì Question:\n",
    "{query}\n",
    "\n",
    "üß† Answer:\"\"\"\n",
    "    prompt = redact_sensitive_info(prompt)\n",
    "\n",
    "    try:\n",
    "        print(\"‚è≥ Sending to OpenRouter, please wait...\")\n",
    "        start = time.time()\n",
    "        response = call_openrouter_api(prompt)\n",
    "        print(f\"‚úÖ Response received in {round(time.time() - start, 2)} seconds\")\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return\n",
    "\n",
    "    # Log\n",
    "    with open(\"qa_log.txt\", \"a\") as f:\n",
    "        f.write(f\"\\nPDF: {selected_pdf}\\nQ: {query}\\nA:\\n{response}\\n{'-'*50}\\n\")\n",
    "\n",
    "    # Print nicely\n",
    "    print(\"\\nüîç Answer:\\n\")\n",
    "    for line in textwrap.wrap(response.strip(), width=80):\n",
    "        print(line)\n",
    "        time.sleep(0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eb4b2cae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìö Available PDFs:\n",
      "1. A hybrid deep learning approach to integrate predictive maintenance.pdf\n",
      "2. A_Cloud-Based_Optimized_Ensemble_Model_for_Risk_Prediction_of_Diabetic_ProgressionAn_Azure_Machine_Learning_Perspective.pdf\n",
      "3. Machine_Learning-Based_Predictive_Maintenance_System_for_Artificial_Yarn_Machines.pdf\n",
      "4. On_the_Performance_of_Machine_Learning_Models_for_Anomaly-Based_Intelligent_Intrusion_Detection_Systems_for_the_Internet_of_Things.pdf\n",
      "‚úÖ Selected: A hybrid deep learning approach to integrate predictive maintenance.pdf\n",
      "‚è≥ Sending to OpenRouter, please wait...\n",
      "‚úÖ Response received in 3.1 seconds\n",
      "\n",
      "üîç Answer:\n",
      "\n",
      "Based on the provided PDF content, the following models are used:  1. The\n",
      "suggested method (integrated model) combines data-driven and model-based\n",
      "approaches. 2. The model-based approach used in the model-based method is based\n",
      "on Weibull distribution. 3. The CNN-LSTM-attention model is used to classify and\n",
      "assign RUL possibility for classifying and assigning the system's state. 4. The\n",
      "linear solver CPLEX is used to solve the production model for solving problems\n",
      "with capacity of multiple products and large size.  It is worth noting that the\n",
      "paper also mentions other models used in other papers, such as those with\n",
      "economic dependence between components, but these are not specifically mentioned\n",
      "in the provided PDF content.\n",
      "\n",
      "üìö Available PDFs:\n",
      "1. A hybrid deep learning approach to integrate predictive maintenance.pdf\n",
      "2. A_Cloud-Based_Optimized_Ensemble_Model_for_Risk_Prediction_of_Diabetic_ProgressionAn_Azure_Machine_Learning_Perspective.pdf\n",
      "3. Machine_Learning-Based_Predictive_Maintenance_System_for_Artificial_Yarn_Machines.pdf\n",
      "4. On_the_Performance_of_Machine_Learning_Models_for_Anomaly-Based_Intelligent_Intrusion_Detection_Systems_for_the_Internet_of_Things.pdf\n",
      "‚úÖ Selected: A_Cloud-Based_Optimized_Ensemble_Model_for_Risk_Prediction_of_Diabetic_ProgressionAn_Azure_Machine_Learning_Perspective.pdf\n",
      "‚è≥ Sending to OpenRouter, please wait...\n",
      "‚úÖ Response received in 7.39 seconds\n",
      "\n",
      "üîç Answer:\n",
      "\n",
      "Based on the PDF content, the models used in the study are:  1. LightGBM 2. LR\n",
      "(Logistic Regression) 3. KNN (K-Nearest Neighbors) 4. CART (Classification and\n",
      "Regression Trees) 5. SVM (Support Vector Machines) 6. Naive Bayes 7. Sequential\n",
      "Neural Network with Adam optimization 8. Adaboost 9. Bagging with KNN 10.\n",
      "Catboost 11. Random Forest 12. XGboost 13. Bayesian Optimization (BO) 14.\n",
      "Genetic Algorithm (GA)  Additionally, the authors also compared the performance\n",
      "of their proposed Ensemble model with the XGboost model, which also produced\n",
      "similar accuracy scores.\n",
      "\n",
      "üìö Available PDFs:\n",
      "1. A hybrid deep learning approach to integrate predictive maintenance.pdf\n",
      "2. A_Cloud-Based_Optimized_Ensemble_Model_for_Risk_Prediction_of_Diabetic_ProgressionAn_Azure_Machine_Learning_Perspective.pdf\n",
      "3. Machine_Learning-Based_Predictive_Maintenance_System_for_Artificial_Yarn_Machines.pdf\n",
      "4. On_the_Performance_of_Machine_Learning_Models_for_Anomaly-Based_Intelligent_Intrusion_Detection_Systems_for_the_Internet_of_Things.pdf\n",
      "‚úÖ Selected: Machine_Learning-Based_Predictive_Maintenance_System_for_Artificial_Yarn_Machines.pdf\n",
      "‚è≥ Sending to OpenRouter, please wait...\n",
      "‚úÖ Response received in 3.66 seconds\n",
      "\n",
      "üîç Answer:\n",
      "\n",
      "Based on the provided PDF content, the following machine learning models were\n",
      "used:  1. Ensemble Learning:         * Random Forest (RF)         * Bagging\n",
      "(Bootstrap AGGregatING) 2. Support Vector Machine (SVM) Algorithm for\n",
      "Regression:         * SVR (Support Vector Regression) 3. Deep Learning (DL)\n",
      "algorithm:         * No specific DL algorithm is mentioned, but Figure 11\n",
      "suggests that the authors used a DL algorithm and computed its accuracy.  These\n",
      "models were used for predicting maintenance indices of artificial yarn machines.\n",
      "\n",
      "üìö Available PDFs:\n",
      "1. A hybrid deep learning approach to integrate predictive maintenance.pdf\n",
      "2. A_Cloud-Based_Optimized_Ensemble_Model_for_Risk_Prediction_of_Diabetic_ProgressionAn_Azure_Machine_Learning_Perspective.pdf\n",
      "3. Machine_Learning-Based_Predictive_Maintenance_System_for_Artificial_Yarn_Machines.pdf\n",
      "4. On_the_Performance_of_Machine_Learning_Models_for_Anomaly-Based_Intelligent_Intrusion_Detection_Systems_for_the_Internet_of_Things.pdf\n",
      "üëã Exiting.\n"
     ]
    }
   ],
   "source": [
    "# ‚úÖ STEP 7: Interactive Multi-PDF Q&A Chat Loop\n",
    "while True:\n",
    "    print(\"\\nüìö Available PDFs:\")\n",
    "    for i, fname in enumerate(filenames):\n",
    "        print(f\"{i + 1}. {os.path.basename(fname)}\")\n",
    "\n",
    "    choice = input(\"\\nüî¢ Enter PDF number to use (or type 'exit'): \")\n",
    "    if choice.lower() == 'exit':\n",
    "        print(\"üëã Exiting.\")\n",
    "        break\n",
    "\n",
    "    try:\n",
    "        selected_pdf = filenames[int(choice) - 1]\n",
    "        retriever = retrievers[selected_pdf]\n",
    "        print(f\"‚úÖ Selected: {os.path.basename(selected_pdf)}\")\n",
    "    except:\n",
    "        print(\"‚ùå Invalid choice. Try again.\")\n",
    "        continue\n",
    "\n",
    "    while True:\n",
    "        question = input(\"\\n‚ùì Ask a question (or type 'back' to choose another PDF): \")\n",
    "        if question.lower() == 'back':\n",
    "            break\n",
    "        ask_question_from_pdf(question, retriever, selected_pdf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84461b60",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
